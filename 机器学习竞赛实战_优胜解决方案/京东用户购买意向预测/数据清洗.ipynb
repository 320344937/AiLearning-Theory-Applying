{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务：京东用户购买意向预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 故事背景：\n",
    "京东作为中国最大的自营式电商，在保持高速发展的同时，沉淀了数亿的忠实用户，积累了海量的真实数据。如何从历史数据中找出规律，去预测用户未来的购买需求，让最合适的商品遇见最需要的人，是大数据应用在精准营销中的关键问题，也是所有电商平台在做智能化升级时所需要的核心技术。\n",
    "\n",
    "以京东商城真实的用户、商品和行为数据（脱敏后）为基础，通过数据挖掘的技术和机器学习的算法，构建用户购买商品的预测模型，输出高潜用户和目标商品的匹配结果，为精准营销提供高质量的目标群体。\n",
    "\n",
    "目标：使用京东多个品类下商品的历史销售数据，构建算法模型，预测用户在未来5天内，对某个目标品类下商品的购买意向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集：\n",
    "这里涉及到的数据集是京东的数据集:\n",
    "\n",
    "* JData_User.csv 用户数据集 105,321个用户\n",
    "* JData_Comment.csv 商品评论 558,552条记录\n",
    "* JData_Product.csv 预测商品集合 24,187条记录\n",
    "* JData_Action_201602.csv 2月份行为交互记录 11,485,424条记录\n",
    "* JData_Action_201603.csv 3月份行为交互记录 25,916,378条记录\n",
    "* JData_Action_201604.csv 4月份行为交互记录 13,199,934条记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JData_User.csv用户数据**\n",
    "\n",
    "|字段|意义|备注|\n",
    "|-|-|-|\n",
    "|user_id|用户id|脱敏|\n",
    "|age|年龄|-1表未知|\n",
    "|sex|性别|0男，1女，2未知|\n",
    "|user_lv_cd|用户等级|级别枚举，越高级别越大|\n",
    "|user_reg_tm|用户注册日期|粒度到天|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JData_Comment.csv评论数据**\n",
    "\n",
    "|字段|意义|备注|\n",
    "|-|-|-|\n",
    "|dt|截止时间|天，到2016-02-01|\n",
    "|sku_id|商品编号|脱敏|\n",
    "|comment_num|累积评论数分段|0表示无评论，1表是1条，2表示2-10条，3表示11-50条，5表示大于50条|\n",
    "|has_bad_comment|是否有差评|0表示无，1表示有|\n",
    "|bad_comment_rate|差评率|差评数占总评论数的比率|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JData_Product.csv商品数据**\n",
    "\n",
    "|字段|意义|备注|\n",
    "|-|-|-|\n",
    "|sku_id|商品编号|脱敏|\n",
    "|a1|属性1|枚举，-1表未知|\n",
    "|a2|属性2|枚举，-1表未知|\n",
    "|a3|属性3|枚举，-1表未知|\n",
    "|cate|品牌ID|脱敏|\n",
    "|brand|品牌ID|脱敏|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JData_Action_xx.csv商品数据**\n",
    "\n",
    "|字段|意义|备注|\n",
    "|-|-|-|\n",
    "|user_id|用户ID|脱敏|\n",
    "|sku_id|商品编号|脱敏|\n",
    "|time|行为时间||\n",
    "|model_id|点击板块的编号|脱敏|\n",
    "|type|行为类型|1.浏览商品详情页;2.加入购物车;3.购物车删除;4.下单;5.关注;6.点击;|\n",
    "|cate|品牌ID|脱敏|\n",
    "|brand|品牌ID|脱敏|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据挖掘流程：\n",
    "（一）.数据清洗\n",
    "1. 数据集完整性验证\n",
    "2. 数据集中是否存在缺失值\n",
    "3. 数据集中各特征数值应该如何处理\n",
    "4. 哪些数据是我们想要的，哪些是可以过滤掉的\n",
    "5. 将有价值数据信息做成新的数据源\n",
    "6. 去除无行为交互的商品和用户\n",
    "7. 去掉浏览量很大而购买量很少的用户(惰性用户或爬虫用户)\n",
    "\n",
    "（二）.数据理解与分析\n",
    "1. 掌握各个特征的含义\n",
    "2. 观察数据有哪些特点，是否可利用来建模\n",
    "3. 可视化展示便于分析\n",
    "4. 用户的购买意向是否随着时间等因素变化\n",
    "（三）.特征提取\n",
    "1. 基于清洗后的数据集哪些特征是有价值\n",
    "2. 分别对用户与商品以及其之间构成的行为进行特征提取\n",
    "3. 行为因素中哪些是核心？如何提取？\n",
    "4. 瞬时行为特征or累计行为特征？\n",
    "\n",
    "（四）.模型建立\n",
    "1. 使用机器学习算法进行预测\n",
    "2. 参数设置与调节\n",
    "3. 数据集切分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集完整性验证\n",
    "首先检查JData_User中的用户和JData_Dction中的用户是否一致，保证行为数据中锁产生的行为均由用户数据中的用户产生。\n",
    "\n",
    "思路：利用pd.Merge连接sku和Action中的sku，观测Action中的数据是否减少Example："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sku  data\n",
      "0   a     1\n",
      "1   a     1\n",
      "2   c     3\n"
     ]
    }
   ],
   "source": [
    "# 测试方法\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'sku':['a','a','e','c'], 'data':[1,1,2,3]})\n",
    "df2 = pd.DataFrame({'sku':['a','b','c']})\n",
    "print(pd.merge(df1,df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果只会打印两者共有的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is action of Feb. from User file?  True\n",
      "Is action of Mar. from User file?  True\n",
      "Is action of Apr. from User file?  True\n"
     ]
    }
   ],
   "source": [
    "#数据集验证\n",
    "def user_action_check():\n",
    "    df_user = pd.read_csv('data/JData_User.csv',encoding='gbk')\n",
    "    df_sku = df_user.loc[:,'user_id'].to_frame()\n",
    "    df_month2 = pd.read_csv('data/JData_Action_201602.csv',encoding='gbk')\n",
    "    # pd.merge(df_sku,df_month2) 会以user_id字段为基准取两个df的交集 不是取并集，这样才能证明 action中的userid 都在df_user里面\n",
    "    print ('Is action of Feb. from User file? ', len(df_month2) == len(pd.merge(df_sku,df_month2))) \n",
    "    df_month3 = pd.read_csv('data/JData_Action_201603.csv',encoding='gbk')\n",
    "    print ('Is action of Mar. from User file? ', len(df_month3) == len(pd.merge(df_sku,df_month3)))\n",
    "    df_month4 = pd.read_csv('data/JData_Action_201604.csv',encoding='gbk')\n",
    "    print ('Is action of Apr. from User file? ', len(df_month4) == len(pd.merge(df_sku,df_month4)))\n",
    "\n",
    "user_action_check() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：User数据集中的用户和交互行为数据集中的用户完全一致\n",
    "\n",
    "根据merge前后的数据量对，能保障Action中的用户ID是User中的ID的子集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查是否有重复记录\n",
    "除去各个数据文件中完全重复的记录,可能解释是重复数据是有意义的，比如用户同时购买多件商品，同时添加多个数量的商品到购物车等…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重复数据\n",
    "def deduplicate(filepath, filename, newpath):\n",
    "    df_file = pd.read_csv(filepath,encoding='gbk')       \n",
    "    before = df_file.shape[0]\n",
    "    df_file.drop_duplicates(inplace=True) # 列相同认为是重复 inplace=True表示在原来的DataFrame上删除重复项4\n",
    "    after = df_file.shape[0]\n",
    "    n_dup = before-after  # 查看前后差值\n",
    "    print ('Number of duplicate records for ' + filename + ' is: ' + str(n_dup))\n",
    "    if n_dup != 0:\n",
    "        df_file.to_csv(newpath, index=None)\n",
    "    else:\n",
    "        print ('Number duplicate records in ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records for Feb. action is: 2756093\n",
      "Number of duplicate records for Mar. action is: 7085038\n",
      "Number of duplicate records for Feb. action is: 3672710\n",
      "Number of duplicate records for Comment is: 0\n",
      "Number duplicate records in Comment\n",
      "Number of duplicate records for Product is: 0\n",
      "Number duplicate records in Product\n",
      "Number of duplicate records for User is: 0\n",
      "Number duplicate records in User\n"
     ]
    }
   ],
   "source": [
    "deduplicate('data/JData_Action_201602.csv', 'Feb. action', 'data/JData_Action_201602_dedup.csv')\n",
    "deduplicate('data/JData_Action_201603.csv', 'Mar. action', 'data/JData_Action_201603_dedup.csv')\n",
    "deduplicate('data/JData_Action_201604.csv', 'Feb. action', 'data/JData_Action_201604_dedup.csv')\n",
    "deduplicate('data/JData_Comment.csv', 'Comment', 'data/JData_Comment_dedup.csv')\n",
    "deduplicate('data/JData_Product.csv', 'Product', 'data/JData_Product_dedup.csv')\n",
    "deduplicate('data/JData_User.csv', 'User', 'data/JData_User_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>time</th>\n",
       "      <th>model_id</th>\n",
       "      <th>cate</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2176378</td>\n",
       "      <td>2176378</td>\n",
       "      <td>2176378</td>\n",
       "      <td>0</td>\n",
       "      <td>2176378</td>\n",
       "      <td>2176378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "      <td>0</td>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>1464</td>\n",
       "      <td>1464</td>\n",
       "      <td>0</td>\n",
       "      <td>1464</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>575597</td>\n",
       "      <td>575597</td>\n",
       "      <td>575597</td>\n",
       "      <td>545054</td>\n",
       "      <td>575597</td>\n",
       "      <td>575597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id   sku_id     time  model_id     cate    brand\n",
       "type                                                       \n",
       "1     2176378  2176378  2176378         0  2176378  2176378\n",
       "2         636      636      636         0      636      636\n",
       "3        1464     1464     1464         0     1464     1464\n",
       "4          37       37       37         0       37       37\n",
       "5        1981     1981     1981         0     1981     1981\n",
       "6      575597   575597   575597    545054   575597   575597"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看重复数据\n",
    "df_month2 = pd.read_csv('data/JData_Action_201602.csv',encoding='gbk')\n",
    "IsDuplicated = df_month2.duplicated()\n",
    "df_d = df_month2[IsDuplicated]\n",
    "df_d.groupby('type').count()  # 发现重复数据大多数都是由于浏览（1），或者点击(6)产生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
