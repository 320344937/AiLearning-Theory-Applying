### 第四章——递归神经网络与词向量原理解读

#### RNN网络架构解读

常规神经网络并不能考虑时间序列的特征（比如前天+昨天+今天或者带有前后关联的特征），现在每个特征都是独立考虑的，那么如果有这样的特征，网络应该怎么学呢

![1609467376667](assets/1609467376667.png)

> 而递归递归网络hidden这里的转回箭头，表示训练完第一个X后，再拿回来去训练第二个X，即前一次训练的结果对后一次的训练结果产生影响。

![1609469515280](assets/1609469515280.png)

> 类似现在有X0、X1、X2 ... Xt，假设X0就是本月的1号，X1就是2号以此类推，Xt就是昨天，这样是不是就是一个时间序列。
>
> X输入后有了h，h是中间的结果，每个h保证能联合前一个的h。



#### LSTM网络

RNN的问题在于，每一次的h只考虑前一个，当h到最后的时候，它只考虑n-1的h，这样对吗？或者说越后面的时间的数据一定越重要吗？我们是不是应该考虑每个时间的数据

![1609470667941](assets/1609470667941.png)

- C：控制参数，决定什么样的信息会被保留什么样的会被遗忘。

- 门：一种让信息选择式通过的方法

- 每次计算的结果和前一轮的结果进行比较，选择要更新的信息

  ![1609470919296](assets/1609470919296.png)

